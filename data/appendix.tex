% !TeX root = ../thuthesis-example.tex

\chapter{补充内容}

%附录是与论文内容密切相关、但编入正文又影响整篇论文编排的条理和逻辑性的资料，例如某些重要的数据表格、计算程序、统计表等，是论文主体的补充内容，可根据需要设置。


\section{定理\ref{thm:DPX}的证明}

\begin{lemma}\label{lem:xyz}
	若 $(X,Y)$ 与 $Z$ $\epsilon$-弱独立，
  则 $X$ 与 $Z$ $\epsilon$-弱独立。
\end{lemma}
\begin{proof}
	由两随机变量$\epsilon$-弱独立的定义式\ref{def:weak_indepedent}，
  我们有
	\begin{equation}\label{eq:pxy_eps}
	P_{X,Y|Z=z}(x,y) = P_{X,Y}(x,y)\left(1+\epsilon \frac{\phi_z(x,y)}{\sqrt{P_{X,Y}(x,y)}}
  \right), z \in \mathcal{Z}
	\end{equation}
	对式\ref{eq:pxy_eps} 关于 $y\in \mathcal{Y}$ 求和我们有
	\begin{equation}
	P_{X|Z=z}(x) = P_X(x)\left(1+\epsilon\frac{\tilde{\phi}_z(x)}{\sqrt{P_X(x)}} \right),
	\textrm{ 其中 } \tilde{\phi}_z(x) = \frac{\sum_{y\in \mathcal{Y}} \sqrt{P_{X,Y}(x,y) }\phi_z(x,y)}{\sqrt{P_X(x)}}
	\end{equation}
	由 柯西不等式, $||\tilde{\phi}_z(x)||^2 \leq \frac{1}{P_X(x)}
	\sum_{y\in \mathcal{Y}}(P_{X,Y}(x,y))
	\sum_{y\in \mathcal{Y}} \phi_z^2(x,y) \leq 1
	$
	从而推出 $X$  与 $Z$ 弱独立。
\end{proof}
\begin{proof}[定理\ref{thm:DPX}的证明]
  由多个随机变量弱独立的定义式 \ref{def:general},
  我们可以找到 一个在字母集 $\{1, 2,\dots, K\}$上的
  离散分布 $U$, 使得 $Z_1, \dots, Z_n$
  关于 $U$ 条件独立。不失一般性，我们假设
  $(Z_1, \dots, Z_n)$ $\epsilon^n$-弱独立。
  则 $(Z_1, \dots, Z_n)$ 和 $U$ $\epsilon$-弱独立，
  由引理 \ref{lem:xyz} 可得 $Z_i$
  和 $U$ $\epsilon$-弱独立，也即有 
\begin{equation}\label{XUk}
P_{Z_i | U=k}(z) = P_{Z_i} (z) \left( 1 + \epsilon {\phi^{(k,i)}(z) \over \sqrt{P_{Z_i}(z)}} \right)
\end{equation}
利用条件独立有
\begin{align}
P_{Z_i, Z_j | U = k}(z_i, z_j)
=& P_{Z_i | U=k}(z_i)
P_{Z_j | U=k}(z_j) \notag \\
=& P_{Z_i}(z_i)P_{Z_j}(z_j)
\left(1 + \epsilon
\left(\frac{\phi^{(k,i)}(z_i)}{\sqrt{P_{Z_i}(z_i)}}
+ \frac{\phi^{(k,j)}(z_j)}{\sqrt{P_{Z_j}(z_j)}}
\right) +
\epsilon^2\frac{\phi^{(k,i)}(z_i)
	\phi^{(k,j)}(z_j)}{\sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)}}
  \right)
  \label{eq:XiXj}
\end{align}
又因为
\begin{align*}
P_{Z_i}(z) &= \sum_{k=1}^{K} P_{Z_i | U=k}(z) P_U(u_k) \\
& =  \sum_{k=1}^{K}P_U(u_k)P_{Z_i} (z)
\left( 1 + \epsilon {\phi^{(k,i)}(z) \over \sqrt{P_{Z_i}(z)}} 
\right) \textrm{ from } \eqref{XUk}\\
\Rightarrow & \sum_{k=1}^{K} P_U(u_k){\phi^{(k, i)}(z) \over \sqrt{P_{Z_i}(z)}} =0,\forall i, z\in \mathcal{Z}
\end{align*}
因此 \eqref{eq:XiXj} 化简为
\begin{equation}\label{eq:PXiXj}
P_{Z_i, Z_j}(z_i, z_j) = P_{Z_i}(z_i)
P_{Z_j}(z_j) \left(
  1+\epsilon^2 \sum_{k=1}^K P_U(u_k)
\frac{\phi^{(k,i)}(z_i)
	\phi^{(k,j)}(z_j)}{\sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)}}
  \right)
\end{equation}
对于2个以上的随机变量:
\begin{align*}
P_{Z_1,\dots,Z_n}(z_1,\dots,z_n)  &= \sum_{k=1}^{K} P_{Z_1,\dots,Z_n | U=k}(z_1,\dots,z_n) P_U(u_k) \\
&=  \sum_{k=1}^{K}P_U(u_k) \prod_{i=1}^n P_{Z_i|U=k}(z_i)\\
&= \sum_{k=1}^{K} P_U(u_k)\prod_{i=1}^n \left(P_{Z_i} (z_i)( 1 + \epsilon {\phi^{(k,i)}(z_i ) \over \sqrt{P_{Z_i}(z_i)}} )\right)\\
&=  \sum_{k=1}^{K}P_U(u_k) (\prod_{i=1}^n  P_{Z_i} (z_i))
\left( 1 + \epsilon\sum_{i=1}^n {\phi^{(k,i)}(z_i) \over \sqrt{P_{Z_i}(z_i)}} + \epsilon^2\sum_{i\neq j}{\phi^{(k,i)}(z_i)\phi^{(k,j)}(z_j)\over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} }\right)+o(\epsilon^2) \\
&= (\prod_{i=1}^n  P_{Z_i} (z_i))
\Big(1+\epsilon\sum_{i=1}^n \sum_{k=1}^{K} P_U(u_k){\phi^{(k,i)}(z_i) \over \sqrt{P_{Z_i}(z_i)}} \\
&+\epsilon^2 \sum_{k=1}^{K} P_U(u_k)\sum_{i\neq j}{\phi^{(k,i)}(z_i)\phi^{(k,j)}(z_j)\over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} } 
\Big) + o(\epsilon^2)\\
&= (\prod_{i=1}^n  P_{Z_i} (z_i))
\left(1 +\epsilon^2\sum_{i\neq j} \sum_{k=1}^{K}P_U(u_k){\phi^{(k,i)}(z_i)\phi^{(k,j)}(z_j)\over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} }\right) + o(\epsilon^2)
\end{align*}
由 \eqref{eq:PXiXj},
令 $B_{ij}(z_i, z_j)={P_{Z_i, Z_j}(z_i,z_j) - P_{Z_i}(z_i)P_{Z_j}(z_j) \over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)}} $ 可得:
\begin{align}
\epsilon^2\sum_{k=1}^{K}P_U(u_k)
{\phi^{k,i}(z_i)\phi^{k,j}(z_j)\over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} } & = {P_{Z_i, Z_j}(z_i, z_j) - P_{Z_i}(z_i)P_{Z_j}(z_j) \over P_{Z_i}(z_i)P_{Z_j}(z_j)} \notag\\
& = {B_{ij}(z_i, z_j) \over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} } \label{eq:Bsecond}
\end{align}
因此，我们有
\begin{equation}\label{eq:sep}
P_{Z_1,\dots,Z_n}(z_1,\dots,z_n) =  (\prod_{i=1}^n  P_{Z_i} (z_i))\left ( 1 + \sum_{i\neq j}{B_{ij}(z_i, z_j) \over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} }\right) +o(\epsilon^2)
\end{equation}
因此 $P_{Z_1,\dots, Z_n}$ 在 $P_{Z_1}\dots P_{Z_n}$ 的
$\epsilon$ 邻域内，且特征函数是
$$\phi(z_1,\dots, z_n)=
\sqrt{P_{Z_1}(z_1)\dots P_{Z_n}(z_n)}
\left(\sum_{i\neq j}{B_{ij}(z_i, z_j) 
\over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} }\right)
+o(\epsilon^2)$$

由 信息几何的式\eqref{eq:approx:ig} 可得
\begin{align*}
D(P_{Z_1,\dots, Z_n}|| P_{Z_1}\dots P_{Z_n}) & ={1 \over 2} \sum_{z_1,\dots,z_n}\phi^2(z_1,\dots, z_n) \\
& = {1\over 2}\sum_{z_1,\dots,z_n} (\prod_{i=1}^n  P_{Z_i} (z_i)) \left(\sum_{i\neq j}{B_{ij}(z_i, z_j) \over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} }\right)^2 +o(\epsilon^2) 
\end{align*}
由 $B_{ij}$
的定义式 \eqref{eq:Ixy}，
上式可化为对 $\norm{B_{ij}}^2_F$
的求和(平方和中的交叉项外面再求和得零)。
因此，对于分割$\P=\{\{i\},i\in V\}$ 我们得到
\begin{equation}
D(P_{Z_1,\dots, Z_n}|| P_{Z_1}\dots P_{Z_n}) =   {1 \over 2} \sum_{i\neq j} \norm{B_{ij}}^2_F + o(\epsilon^2)
\end{equation}
对于任意的分割 $\P$，
由式\eqref{eq:sep}可得，对于 $C\in \P$，
我们有
\begin{equation}
P_{Z_C}(z_C) = \prod_{i\in C} P_{Z_i}(z_i)
\left(1 + \epsilon^2 \sum_{i\neq j,i,j\in C} \frac{B_{ij}(z_i, z_j)}{\sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)}}
\right) + o(\epsilon^2)
\end{equation}
将上式相乘可得:
\begin{equation}
\prod_{C\in \P}P_{Z_C}(z_C) = \prod_{i=1}^n P_{Z_i}(z_i)
\left(1+\epsilon^2 \sum_{C\in\P}\sum_{i\neq j,i,j\in C}\frac{B_{ij}(z_i, z_j)}{\sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)}}
\right) + o(\epsilon^2)
\end{equation}
所以 $\prod_{C\in \P}P_{Z_C}$ 在 $P_{Z_1}\dots P_{Z_n}$ 的$\epsilon$ 邻域内，
且 $$\phi_{\P}(z_1,\dots, z_n)=
\sqrt{P_{Z_1}(z_1)\dots P_{Z_n}(z_n)}\left(\sum_{C\in\P}\sum_{i\neq j,i,j\in C}\frac{B_{ij}(z_i, z_j)}{\sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)}}\right)+o(\epsilon^2)$$
由  \eqref{eq:approx:ig} 得:
\begin{align*}
D(P_{Z_1,\dots, Z_n}|| \prod_{C\in \P}P_{Z_C}) & ={1 \over 2} \sum_{z_1,\dots,z_n}(\phi(z_1,\dots, z_n)-\phi_{\P}(z_1, \dots, z_n))^2 \\
& = {1\over 2}\sum_{z_1,\dots,z_n} \prod_{i=1}^n  P_{Z_i} (z_i) \left(\sum_{\substack{(i,j) \not\in C\\ C\in \P}} {B_{ij}(z_i, z_j) \over \sqrt{P_{Z_i}(z_i)P_{Z_j}(z_j)} }\right)^2 +o(\epsilon^2) \\
& = \frac{1}{2} \sum_{\substack{(i,j) \not\in C\\ C\in \P}} \norm{B_{ij}}_F^2 + o(\epsilon^2)
\end{align*}
\end{proof}



\section{定理\ref{thm:triangle} 的证明}
首先我们证明如下引理：
\begin{lemma}\label{thm:trival}
  分割 $\P_k = \{\{1\},\{2\},\dots,\{\abs{V}\}\}$ 
  使得 $\frac{f[\P]}{\abs{\P}-1}$
  最小 当且仅当 条件\eqref{eq:GF} 成立。
  \begin{equation}\label{eq:GF}
  \frac{f[\P]}{\abs{\P}-1} \geq \frac{f[\P_k]}{\abs{V}-1} \textrm{ for any } \P \in \Pi'
  \end{equation}
  \end{lemma}
  \begin{proof}
  由\citet{narayanan} 的定理3可知，
  $h(\lambda)$ 是分段线性函数，
  $h(\lambda)$ 的第一段
  是 $ - \lambda $ 且 
  最后一段是 $ f[\P_k] - \abs{V} \lambda$。
  它们的交点是
  $(\lambda_{+}, -\lambda_{+})$，
  其中
  $\lambda_{+} = \frac{f[\P_k]}{\abs{V}-1}$。
  因为 $\frac{f[\P]}{\abs{\P}-1} \geq \lambda_{+} \iff f[\P] - \abs{\P}\lambda_{+} \geq - \lambda_{+}$，
  方程 \eqref{eq:GF}
  相当于说 $h(\lambda)$ 在 $\lambda = \lambda_{+}$
  的最小值点是
  $\{V\}$ 或
  $\{\{1\},\{2\},\dots,\{\abs{V}\}\}$
  并且 $h(\lambda)$ 只有两段。
  从几何的观点来看，$\min\frac{f[\P]}{\abs{\P}-1}$
  是 $h(\lambda)$ 第一个分界点，
  该分界点与$h(\lambda)$最后一个分界点
  相等 当且仅当 \eqref{eq:GF} 成立。
  \end{proof}


\section{数据集}
Gaussian 数据集是用\texttt{scikit-learn}
\cite{scikit-learn}
的 make\_blobs 函数生成，每类25个数据点，共4类。
其中心分别为$[3,3],[-3,-3],[3,-3],[-3,3]$，
标准差均为1。

Circle 数据集共3类，每一类的数据点个数分别为 $[60,100,140]$，
并使用如下的极坐标公式生成：
\begin{align*}
r &= 0.1 \times i + 0.01(2u-1), i = 1, 2, 3\\
\theta & = 2\pi v
\end{align*}
其中 $u,v$ 是 $[0,1]$ 间的随机数，彼此独立。

Gaussian-blob 数据集与 Gaussian 数据集
的区别在于每类$n$个数据点，其中$n=[1,2,3,4,5]*100$。

Two-level graph 数据集中取参数
$z_{\mathrm{in}_1}=s^2-2,
z_{\mathrm{in}_2}=s-1,
z_{\mathrm{out}}=1$，其中$s=[3,4,5,6,7]$。