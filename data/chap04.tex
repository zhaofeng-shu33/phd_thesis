% !TeX root = ../thuthesis-example.tex

\chapter{基于速率函数的随机块模型精确恢复问题研究}\label{chap:sibm}
\section{本章引言}
本章将利用速率函数这一信息论的度量研究
具有多个社团结构的随机块模型。具体来说，
我们的研究对象是
定义 \ref{def:SSBM} 中的 $\SSBM(n,k,\A, \B)$。
我们在之前的讨论中指出，当$\sqrt{a}-\sqrt{b}>\sqrt{k}$，即式 \eqref{eq:abk} 成立
时，存在实现精确恢复的算法，但实际问题中我们得到的是
随机块模型的实例，并没有$a,b$参数的信息，因此
我们在本章首先研究如何估计模型的参数 $a,b$。
此外，对于其他更高效的恢复算法，实现精确恢复的算法不一定由 式\eqref{eq:abk}
给出。
本章将研究一个具有辅助双参数$\beta,\gamma$ 的社团发现算法，
我们称之为基于玻茨模型的社团发现算法，
在研究这一算法的过程中，我们将展示如何利用速率函数刻画其精确恢复条件
和误差衰减率等性质。进一步地，我们将研究由玻茨模型
衍生出的社团发现算法的误差率，我们称该方法为基于能量最小化的社团发现算法。
上述算法便于理论分析但实际实现需要近似求解的算法。
为此，我们采用梅特罗波利斯采样算法进行近似，
通过该近似算法的实验结果我们将验证$\beta$参数对误差率的影响。

本章内容的具体安排如下：
在 \ref{sec:parameter_estimation} 节，我们首先研究了
随机块模型的超参估计问题；
在 \ref{sec:potts} 节，我们研究了基于玻茨模型的社团发现算法
的相变现象和恢复误差；接下来，
在 \ref{sec:em} 节，我们分析了基于能量最小化的社团发现算法
的恢复误差；在 \ref{sec:ms} 节，用梅特罗波利斯采样对
玻茨模型的相变现象进行了验证；
第 \ref{sec:summary_potts} 节对全章进行了总结。
\section{参数估计}\label{sec:parameter_estimation}


本节中，我们考虑 $\SSBM(n,k,\A, \B)$ 模型的参数估计
问题。关于 随机块模型 的参数估计问题也有相关的研究工作。
在几乎一致恢复的场景下 Mossel 提出了参数 $(a,b)$ 的一个一致估计量
\cite{mossel2015reconstruction}。
而对于精确恢复的情形，通常可以先恢复节点的标签，再估计模型参数
\cite{abbe2015recovering}。

假设 $k$ 已知，
我们想从图 $G$ 中估计
$a$ 和 $b$。
我们提出的方法如下，首先
对$G$中 边的数量 $T_1$ 
和 三角形的数量
$T_2$进行计数，然后通过求解下述
关于$(x,y)$的非线性方程组得到
估计量 $\hat{a}, \hat{b}$：
\begin{equation} \label{eq:e_1}
\left\{
	\begin{alignedat}{1}
	\frac{x+(k-1)y}{2k}  &= \frac{T_1}{n\log n} \\
\frac{1}{k^2}
\left(\frac{x^3}{6} + \frac{k-1}{2}xy^2 + (k-1)(k-2)\frac{y^3}{6}\right)
 &= \frac{T_2}{\log^3 n}
	\end{alignedat}
\right.
\end{equation}


解的理论保证由如下定理给出：
\begin{theorem}\label{thm:ab12}
当 $n$ 足够大时，
关于方程组\eqref{eq:e_1}
有唯一解 $(\hat{a}, \hat{b})$，
\newglossaryentry{consistent_est}{name=一致估计量, description={Consistent estimator}}
并且该解是参数$(a,b)$的\gls{consistent_est}，
也即 $\hat{a}, \hat{b}$ 
分别依概率收敛到 $a,b$ 。
\end{theorem}
给定一个由随机块模型生成的图，
我们可以用定理 \ref{thm:ab12} 获得参数$a,b$ 
的估计量，然后用 \eqref{eq:abk}
式
来判断标签$X$ 的精确恢复是否可能。
此外，对于有限规模的图，定理 \ref{thm:ab12} 提供的 $a,b$ 的估计可用于
初始化某些恢复算法的相关参数，
比如最大似然估计或者我们
将在 \ref{sec:ms} 节使用的梅特罗波利斯算法。

下面我们通过实验来验证
定理 \ref{thm:ab12} 的结果。我们考虑若干组不同的
$(a,b,k)$ 的组合，对于每一种取值，
通过定理 \ref{thm:ab12} 我们可得到估计量
\newacronym{acr:mse}{MSE}{Mean Square Error}
$(\hat{a}, \hat{b})$，进而计算
均方误差(\gls{acr:mse})
$\frac{1}{m} \sum_{i=1}^m (\hat{a}-a)^2 + (\hat{b}-b)^2$。
这里  采样次数$m$ 取 $1000$。
实验结果 如
图 \ref{fig:estimator} 所示。
由此可见， 随着 $n$ 的增大，
均方误差 以多项式的速率减小。
从而验证了 $\hat{a}, \hat{b}$ 分别收敛到 $a,b$ 
的结果。

\begin{figure}[ht!]
	\centering
		\includegraphics[width=0.6\textwidth]{estimator-error-2023-03-10.pdf}
		\caption{ $\hat{a}, \hat{b}$ 的估计误差随
		$n$ 的变化规律 }\label{fig:estimator}
\end{figure}

\section{基于玻茨模型的社团发现算法}\label{sec:potts}
\subsection{算法描述}
类似于 \ref{sec:ising} 节
介绍的SIBM模型，我们将
随机块模型
与 \ref{sec:ising} 节介绍的 玻茨模型
复合起来可得到随机块-玻茨模型。该模型可以看成是SIBM模型的推广，
每个节点由两状态变成了多状态。由于我们的研究重点并非
从随机块-玻茨模型的多个样本恢复节点的原始标签，而是利用
玻茨模型对随机块模型进行社团发现，因此我们首先给出
在随机块模型生成的图上定义的玻茨模型：
\begin{definition}\label{def:ising}
	给定从$\SSBM(n,k,\A,\B)$ 中生成的随机图 $G$，
    定义在$G$上的玻茨模型（$k$个状态的伊辛模型）是关于状态向量$\sigma\in W^n$ 的概率分布
。该分布有两个参数 $\beta, \gamma>0$，其概率质量函数为
\begin{align} \label{eq:isingma}
	P_{\sigma|G}(\sigma=\bar{\sigma})=\frac{\exp(-\beta H(\bar{\sigma}))}{Z_G(\beta, \gamma)}
	\end{align}
其中能量函数$H(\bar{\sigma})$的定义是
\begin{equation}\label{eq:energy}
	H(\bar{\sigma}) := \gamma \frac{\log n}{n} \sum_{\{i,j\}\not\in E(G)} \delta(\bar{\sigma}_i, \bar{\sigma}_j)
	- \sum_{\{i,j\}\in E(G)} \delta(\bar{\sigma}_i, \bar{\sigma}_j)
	\end{equation}
	
	$P_{\sigma|G}$ 中的下标表示该分布依赖于$G$，
    $Z_G(\beta, \gamma)$ 是该分布的归一化常数。
\end{definition}

式\eqref{eq:isingma}中
各符号的含义同式\eqref{eq:canonical_ensemble}。
而表示汉密尔顿能量的式\eqref{eq:energy}
则是式\eqref{eq:ising_modified}的推广。
当  $k=2$ 时，式 \eqref{eq:energy}
在注释 \ref{rem:equivalence_H_energy} 的意义下
退化成 式 \eqref{eq:ising_modified}。 

这里的能量函数$H(\bar{\sigma})$ 同样有两部分组成：
没有边相连的节点之间排斥力的势能和
有边相连的节点之间吸引力的势能。
$\gamma$ 是没有边相连的节点间的作用力系数。
考虑到两节点间有边相连的概率仅为 $O(\frac{\log n}{n})$，
$\frac{\log n}{n}$ 是对由于边的数量不均匀造成两种势能量阶不同的修正项。


定义 \ref{def:ising} 实际上给出了一个估计$X$的随机算法 $\hat{X}^*$。
这里，$\hat{X}^*$ 表示产生于玻茨模型的一个样本，
记作$\hat{X}^* \sim \textrm{Potts}_G(\beta, \gamma)$。
下面我们首先研究$\hat{X}^*$实现精确恢复的条件及误差上界，
而关于如何进行玻茨模型的采样我们将在后面进行讨论。
\subsection{误差的渐近性质}
沿用注释 \ref{rem:metric_exact_recovery} 中的记号，
使用$\hat{X}^*$估计$X$在精确恢复度量下的错误概率
记为 $P_e(\hat{X}^*) := \sum_{G \in \cG_n} P_G(G) P_{\sigma | G}(S^c_k(X))$。
类似文献 \inlinecite{ye2020exact} 中关于 SIBM 模型的讨论，
玻茨模型的两个参数$(\beta, \gamma)$ 的取值
对$P_e(\hat{X}^*)$
也有着决定性的作用。
当它们取合适的值时， 
$ P_e(\hat{X}^*)\to 0$，
随机块模型的精确恢复可以实现。
反之，如果 $(\beta, \gamma)$ 取其他值时，
$P_e(\hat{X}^*) \to 1$。
这两种情况可总结为如下的定理：

\begin{theorem}\label{thm:phase_transition}
	假设 $\sqrt{a} - \sqrt{b} > \sqrt{k}$，
	定义函数 $g(\beta)$ 和 $ \tilde{g}(\beta)$ 如下：
	\begin{equation}
		\label{eq:g_beta_main_article}
		g(\beta) = \frac{be^{\beta} + a e^{-\beta}}{k} - \frac{a+b}{k} +1
	\end{equation}
	且
	\begin{equation}
		\label{eq:g_tilde_beta_main_article}
	\tilde{g}(\beta) = \begin{cases}
	g(\beta) & \beta \leq \bar{\beta} = \frac{1}{2}\log \frac{a}{b} \\
	g(\bar{\beta}) = 1 - \frac{\left(\sqrt{a} - \sqrt{b}\right)^2}{k} & \beta > \bar{\beta}
	\end{cases}
	\end{equation}
	其中
	$\bar{\beta} =  \displaystyle\argmin_{\beta > 0} g(\beta)$。
	令 $\beta^*$ 定义成
	\begin{equation}\label{eq:beta_star}
	\beta^* = \log\left(\frac{a + b - k - \sqrt{(a + b - k)^2 - 4 a b)}}{2  b}\right)
	\end{equation}
	可以验证 $\beta^*$ 是方程 $g(\beta) = 0$ 的解 并且满足  $\beta^* < \bar{\beta}$。	
	设 $G\sim \SSBM(n, k, \A, \B)$， $\hat{X}^* \sim \textrm{Potts}_G(\beta, \gamma)$，
	对于给定的 $\epsilon > 0$， 当 $n$ 充分大时， 我们有：
	\newglossaryentry{not:small_o}
	{
	  type=notation,
	  name={$o(1)$},
	  description={无穷小量}
	}
	\begin{enumerate}
	\item 当 $\gamma > b$ 且 $\beta > \beta^*$ 时，$P_e(\hat{X}^*) \leq n^{\tilde{g}(\beta)/2 + \epsilon}$；
	\item 当 $\gamma > b$ 且 $\beta < \beta^*$ 时，$P_a(\hat{X}^*) \leq (1+$\gls{not:small_o}$)\max\{n^{g(\bar{\beta})}, n^{-g(\beta) + \epsilon}\}$；
	\item 当 $\gamma < b$ 时，对于任意给定的 $C>0$	均有 $P_a(\hat{X}^*) \leq \exp(-C n)$。
	\end{enumerate}
\end{theorem}

\begin{figure}[H]
	\begin{subfigure}{0.43\textwidth}
		\includegraphics[width=\textwidth]{g-16-4-2.pdf}
		\caption{当 $a=16,b=4,k=2$时，$g(\beta)$和
		$\tilde{g}(\beta)$的函数图像}\label{fig:g}
	\end{subfigure}~
	\begin{subfigure}{0.55\textwidth}
		\includegraphics[width=\textwidth]{phase_trans_chinese.pdf}
		\caption{
			在 $(\beta, \gamma)$ 平面内
			相变区域图示。
			随机块模型的精确
			恢复仅在区域 I 可实现。}\label{fig:pt}
	\end{subfigure}
	\caption{定理 \ref{thm:phase_transition} 
	的图示}
	\label{fig:phase_transition_theorem_illustration}
\end{figure}
\begin{remark}
	在式\eqref{eq:g_beta_main_article} 中，我们首次引入了
	$g(\beta)$ 这个函数，该函数是由矩生成函数导出的，
	其信息学含义为速率函数的凸共轭函数，
	具体我们将在 \ref{sub:rate_function} 小节专门讨论。
\end{remark}
%与式\eqref{eq:beta_star_sibm}的情形类似，
注意到条件$\sqrt{a} - \sqrt{b} > \sqrt{k}$使得
式\eqref{eq:beta_star}中根号下的项非负。
这个条件来自于定理 \ref{thm:sbmk_phase_transition}，
保证了随机块模型本身精确恢复可实现。


通过简单的计算可知，对于 $\beta> \beta^*$，
我们有 $\tilde{g}(\beta) < 0$，
而 对于 $\beta < \beta^*$，有
$g(\beta)>0$。
另外，由 $\sqrt{a} - \sqrt{b} > \sqrt{k}$ 可知
$g(\bar{\beta}) < 0$。
$g(\beta), \tilde{g}(\beta)$ 的图像
如图 \ref{fig:phase_transition_theorem_illustration} (a)所示。
因此， 对于充分小的
$\epsilon$ 并且当 $n \to \infty$，
定理 \ref{thm:phase_transition} 中给出的上界
均至少以多项式的速度趋向于 $0$。
从而定理 \ref{thm:phase_transition} 刻划了
玻茨模型的相变性质。
如图 \ref{fig:phase_transition_theorem_illustration} (b)所示
， 对于玻茨模型， 只有参数$(\beta, \gamma)$落在区域I时，
随机块模型的精确
恢复才能实现。



定理 \ref{thm:phase_transition} 中的$k=2$与
文献\inlinecite{ye2020exact}的定理2中的$m=1$时
的结论是一致的。此外，
定理 \ref{thm:phase_transition} 也
可以从$\sigma$的边缘分布的角度理解。
玻茨模型取到某个特定状态$\bar{\sigma}$的概率为
 $\sigma: P_{\sigma}(\sigma =\bar{\sigma})
=\sum_{G \in \cG_n}P_G(G)P_{\sigma |G}(\sigma=\bar{\sigma})$。
\newglossaryentry{not:sigma_nearest_to_the_latter}
{
  type=notation,
  name={\ensuremath{D(\sigma, \sigma')}},
  description={$\sigma$ 相比于它的所有置换其本身离 $\sigma'$ 最近
  这个事件}
}
我们用符号 \gls{not:sigma_nearest_to_the_latter} 表示 \glsdesc{not:sigma_nearest_to_the_latter}
。
也即
\begin{equation}
	\label{eq:D_sigma_sigma_prime}
D(\sigma, \sigma') := \{  \Dist(\sigma, \sigma')  = \min_{f \in S_k} \Dist(f(\sigma), \sigma')  \}
\end{equation}

则 定理 \ref{thm:phase_transition} 对边缘分布 $P_{\sigma}$ 蕴含着如下的论断
：
\begin{corollary}\label{cor:phase4}
假设 $\gamma > b$， 取决于 $\beta$ 的取值我们有
\begin{enumerate}
	\item 当 $\beta > \beta^*$时，$P_{\sigma}(\sigma = X | D(\sigma, X))  = 1-o(1)$；
	\item 当 $\beta < \beta^*$时，$P_{\sigma}(\sigma = X | D(\sigma, X))  = o(1)$。
\end{enumerate}
\end{corollary}

下面我们简单阐述下 定理 \ref{thm:phase_transition} 证明的思路。
该思路主要通过对翻转一个状态的前后能量差的分析来估计概率的主项。
下面的引理总结了翻转一个状态前后汉密尔顿能量的变化：
\begin{lemma}\label{lem:lemmaDiff}
	假设 $\bar{\sigma}'$ 仅在第$r$个位置上与 $\bar{\sigma}$ 不同，
	差别为 $\bar{\sigma}'_r = \omega^s \cdot \bar{\sigma}_r$。
	则 $\bar{\sigma}'$ 和 $\bar{\sigma}$ 的能量差为
\begin{align}
	H(\bar{\sigma}') - H(\bar{\sigma}) &= \left(1+\gamma \frac{\log n}{n} \right)
	\sum_{i \in N_r(G)} J_s(\bar{\sigma}_r, \bar{\sigma}_i)
	+ \gamma \frac{\log n}{n} (m(\omega^s \cdot \bar{\sigma}_r)-m(\bar{\sigma}_r)+1) \label{eq:DeltaH}
	\end{align}
	上式中 $m(\omega^j) := \left|\left\{i \in [n] | \bar{\sigma}_i = \omega^j \right\} \right| $，
	$N_r(G):=\{j | (r, j) \in E(G) \}$ 表示节点$r$
	的邻居节点，
	而 $J_s(x, y) = \delta(x, y) - \delta(\omega_s \cdot x, y)$。
\end{lemma}
\begin{proof}
	首先我们将
  \eqref{eq:energy} 式改写成
	\begin{equation*}
	H(\bar{\sigma}) = \gamma \frac{\log n}{n} \sum_{i < j} \delta(\bar{\sigma}_i, \bar{\sigma}_j)
	- \left(1 + \gamma\frac{\log n}{n} \right)
	\sum_{ \{i, j\} \in E(G)} \delta(\bar{\sigma}_i, \bar{\sigma}_j)
	\end{equation*}
	
	接着我们逐步计算能量差：
  \begin{align*}
	H(\bar{\sigma}') - H(\bar{\sigma}) =& 
  \left(1 + \gamma\frac{\log n}{n}
  \right)
  \cdot \sum_{i \in N_r(G)} (\delta(\bar{\sigma}_r, \bar{\sigma}_i) -
	\delta(\omega^s \cdot \bar{\sigma}_r, \bar{\sigma}_i)) \\
	&+ \gamma \frac{\log n}{n}\sum_{i\neq r}
	( \delta(\omega^s \cdot \bar{\sigma}_r, \bar{\sigma}_i) -
	\delta( \bar{\sigma}_r, \bar{\sigma}_i) ) \\
	 =& \left(
     1 + \gamma\frac{\log n}{n}
     \right)
   \sum_{i \in N_r(G)} J_s(\bar{\sigma}_r, \bar{\sigma}_i) \\
	&+ \gamma \frac{\log n}{n}\sum_{i=1}^n
	( \delta(\omega^s \cdot \bar{\sigma}_r, \bar{\sigma}_i) -
	\delta( \bar{\sigma}_r, \bar{\sigma}_i) +1) \\
	=& \left(1+\gamma \frac{\log n}{n}
  \right)
  \sum_{i \in N_r(G)} J_s(\bar{\sigma}_r, \bar{\sigma}_i)\\
	&+ \gamma \frac{\log n}{n} (m(\omega^s \cdot \bar{\sigma}_r)-m(\bar{\sigma}_r)+1)
	\end{align*}
\end{proof}
\begin{remark}\label{re:energy_diff}
	当 $\bar{\sigma}'$ 与 $X$ 仅在位置 $r$
	上不同时， 在引理 \ref{lem:lemmaDiff} 中
	取$\bar{\sigma}=X$，
	结合条件  $|\{v \in [n] | X_v = u\}| = \frac{n}{k}$，
	有 $m(\omega^s \cdot \bar{\sigma}_r)
	=m(\bar{\sigma}_r)$，
	进而：
	\begin{equation}\label{eq:energy_diff}
	H(\bar{\sigma}') - H(X) = \left(1+\gamma \frac{\log n}{n} \right)
	(A^0_r - A^s_r) + \gamma\frac{\log n}{n}
	\end{equation}
	其中 $A^s_r$ 定义成
	$A^s_r := |\{j \in [n]\backslash \{r\}: \{j, r\} \in E(G), X_j = \omega^s \cdot X_r \}|$。
	因为$G$中各边的存在与否是独立的，
	对于 $s\neq 0$
	我们有 $A^s_r \sim \Binom \left(
	  \frac{n}{k}, \B \right) $，
	而 $A^0_r \sim \Binom
	\left(
	  \frac{n}{k}-1, \A \right)$。	
\end{remark}
考虑到：
\begin{equation}\label{eq:Pratio}
\frac{P_{\sigma |G } (\sigma = \bar{\sigma}')}{P_{\sigma |G } (\sigma = \bar{\sigma})}
= \exp(-\beta(H(\bar{\sigma}') - H(\bar{\sigma})))
\end{equation}
因此引理 \ref{lem:lemmaDiff} 提供了用以比较两个相邻状态的概率
的方法。当 $n$充分大时，我们注意到式
\eqref{eq:Pratio} 右端化为$\exp(-\beta (A_r^0 - A_r^s))$。
而如果我们对其取期望，则可以得到
\begin{equation}\label{eq:expect_A_r_0_s}
	\E[\exp(-\beta (A_r^0 - A_r^s))] \sim n^{g(\beta)-1}
\end{equation}
也即 $g(\beta)$与两个二项分布差$A_r^0 - A_r^s$的矩生成函数有关。



另外， 我们注意到 因为图中边的数量是稀疏的，每个节点
平均有 $O(\log n)$ 个相连的邻居节点。
按照式 \eqref{eq:DeltaH} 
计算能量差的时间复杂度也是 $O(\log n)$。

当 $H(\bar{\sigma}') > H(\bar{\sigma})$ 时， 
由式\eqref{eq:Pratio} 可得
$P_{\sigma | G}(\sigma = \bar{\sigma}')<P_{\sigma | G}(\sigma = \bar{\sigma})$。
粗略而言， 如果
$ \sum_{\Dist(\sigma', X)=1}\exp(-\beta(H(\bar{\sigma}') - H(X))) $
收敛到零，
我们可以预期，与$S_k(X)$不同的所有其他状态的概率收敛到零，
即$P_{\sigma}(S_k(X))$趋于1。
与之相反， 如果
$ \sum_{\Dist(\sigma', X)=1}\exp(-\beta(H(\bar{\sigma}') - H(X))) $
趋于无穷大，
则 $P_{\sigma}(S_k(X))$ 趋于零。
此种分析展示了证明定理 \ref{thm:phase_transition} 的
主要思路。应用这一思路，由式
\eqref{eq:expect_A_r_0_s}，
当$n$充分大时，$ \sum_{\Dist(\sigma', X)=1}\exp(-\beta(H(\bar{\sigma}') - H(X))) $
的数学期望为 $n^{g(\beta)}$，
通过讨论$g(\beta)$的正负可以部分说明
定理 \ref{thm:phase_transition} 中的表述。
\subsection{速率函数}\label{sub:rate_function}
在\eqref{eq:expect_A_r_0_s} 中我们指出了$g(\beta)$与
二项分布差$A_r^0 - A_r^s$的矩生成函数有关，本节将进一步挖掘
其信息论的含义。

首先，通过切尔诺夫不等式的方法
（证明见附录引理 \ref{lem:enhanced_fb} ），
我们有
\begin{equation}\label{eq:introduction_g_a_b_eps}
  P_G(A_r^s - A_r^0 \ge t  \log n) 
	\le  \exp\left(-\log n \cdot
	\left(
   \frac{1}{k} g(a,b,kt) + O\left((\log n)^{-\delta} \right) \right)\right)
\end{equation}
其中 函数 $g(a,b,\epsilon)$ 的定义为
\begin{equation}  \label{equation:g}
  g(a,b,\epsilon) \triangleq a + b - \sqrt{\epsilon^2 + 4ab} + \epsilon \log \frac{\epsilon + \sqrt{\epsilon^2 + 4ab}}{2b}
\end{equation}
其等价形式亦可参见 文献\inlinecite{abbe2015exact} 中的 式 (43)
。
易验证
% $\frac{g(a,b,kt)}{k}=-[f_{\beta}(t)-\beta t -1]$。
%实际上
$g(a,b,s)$ 和 $g(s)-1$ 互为凸共轭函数（定义 \ref{def:convex_conjugate} ）。

利用凸共轭函数的概念，
下面我们引入大偏差理论中的 Gärtner Ellis 定理
来获得 $g(a,b,\epsilon)$。Gärtner Ellis 定理是
Cramér 定理（定理 \ref{thm:cramer} ）的推广，
其一般情形下的表述可参见
文献\inlinecite{dembo2009large}。
我们这里仅给出 Gärtner Ellis 定理的一个特例形式。

令 $S_n$ 为随机变量的序列，
$\gamma_n >0, \lim_{n\to \infty}\gamma_n \to \infty$。
$\Lambda_n(t)=\log \E[\exp(t S_n)]$ 代表 $S_n$ 的对数矩生成函数。
假设对于任意的 $t$，
$\Lambda(t) =\lim_{n\to \infty} \frac{1}{\gamma_n}\Lambda_n(\gamma_n t)$
存在。 令 $\Lambda^*$ 是 $\Lambda$ 的共轭函数。
则对于任意 紧集 $\Gamma \subset \mathbb{R}$，
我们有
\begin{equation}\label{eq:gartner_ellis}
\lim_{n\to \infty} \frac{1}{\gamma_n}\log P(S_n \in \Gamma) = -\inf_{s \in \Gamma} \Lambda^*(s)
\end{equation}
仿照 Cramér 定理中速率函数的概念，这里我们也把$\Lambda^*(s)$叫做速率函数。

下面我们应用式 \eqref{eq:gartner_ellis}
导出 $g(a,b,\epsilon)$ 的
表达式。
我们取 $\gamma_n= \log n$ 且 $\gamma_n S_n = \sum_{i=1}^n Y_i$，$Y_i=Z_i - W_i$，
$Z_i, \dots, Z_n$ 是 i.i.d. $\Bern\left(\B\right)$ 而 $W_1, \dots, W_n$ 是 i.i.d. $\Bern\left(\A\right)$。
$Y_i$ 的概率质量函数可表示为 $[(1-q)p, qp+(1-p)(1-q), q(1-p)]$，对应 $[-1,0,1]$ 三个取值。
首先我们计算得到 
$\Lambda(t) = \lim_{n\to \infty} \frac{n}{\log n} \log \E[\exp(t Y_1)]
=-a-b+be^t  + ae^{-t}$。
由 $\Lambda^*(s) = \sup_{t\in\mathbb{R}}\ st - \Lambda(t)$，
我们进一步得到 $\Lambda^*(s) = g(a,b,s)$。

在我们的问题中， $\Gamma=[t, +\infty)$ 。
考虑到 $\Lambda^*(s)$  是$[0,+\infty)$ 上的增函数，
我们有
\begin{equation}
  \lim_{n\to \infty} \frac{1}{\log n} P(S_n \ge t \log n)
  = g(a,b,t)
\end{equation}
该结果是式\eqref{eq:introduction_g_a_b_eps} 中 $k=1$结果的极限情况。
特别地，当$t=0$ 时， $g(a,b, 0) = \left(\sqrt{a} - \sqrt{b}\right)^2$。

\section{基于能量最小化的社团发现算法}\label{sec:em}
因为 $\beta^*$ 和 $n$ 无关，
当 $\gamma>b$ 时，
我们可以选取一个足够大的 $\beta$ 使得
$\beta > \beta^*$，
则 由 定理 \ref{thm:phase_transition}，
当$n$充分大时 $\sigma \in S_k(X)$ 几乎必然发生。
这蕴含了 $P_{\sigma | G}(\sigma = X)$
对于几乎所有 从 随机块模型生成的图  $G$来说 取得最大值。
因此
相比于从玻茨模型中采样的方法，我们可以直接最大化条件概率，以
找到概率最大值的状态。
等价地， 我们可以通过最小化 式\eqref{eq:energy}来获得状态的估计量：
\begin{equation}\label{eq:hatX}
\hat{X}' := \argmin_{\bar{\sigma} \in W^n} H(\bar{\sigma})
\end{equation}

在 \eqref{eq:hatX} 中， 我们让 $\bar{\sigma}$ 在 $W^n$ 中取值。
因为我们已知 $X$取各个标签的位置数相等，即对于每个标签值 $u$
有 $|\{v \in [n] : X_v = u\}| = \frac{n}{k}$，
我们可以把搜索空间限制到
$W^*:= \left\{\sigma\in W^n \big\vert |\{v \in [n] : \sigma_v = \omega^s\}| = \frac{n}{k}, s=0,\dots, k-1 \right\}$
上。
当 $\sigma \in W^*$ 时， 最小化 $H(\sigma)$ 等价于：
\begin{equation}\label{eq:hatX_double_prime}
\hat{X}'' := \argmin_{\sigma \in W^*} \sum_{\{i,j\} \not\in E(G) } \delta(\sigma_i, \sigma_j)
\end{equation}
其最小值是不同社团之间的最小分割。

当 $\hat{X}'' \neq X$ 时，
我们必须有  $\Dist(\hat{X}'' ,X)\geq 2$
以满足 硬约束 $\hat{X}'' \in W^*$。
此外，估计量 $\hat{X}''$ 是无参的而 $\hat{X}'$的值受
参数 $\gamma$ 的影响。
在
$\hat{X}'$ 的表达式中出现的额外的参数 $\gamma$ 可视为
某种整数规划的拉格朗日乘子。
因此，通过引入惩罚因子项和将搜索空间从$W^*$ 扩大 到$W^n$
，求解 $\hat{X}''$
的优化问题 转变为求解 $\hat{X}'$的问题。

当 $\beta > \bar{\beta}$ 时，
$\tilde{g}(\beta)$ 是一个常数。
因此，从定理 \ref{thm:phase_transition} 中我们可以获得的关于
玻茨模型的估计量 $\hat{X}^*$ 最紧的上界
是  $n^{g(\bar{\beta})/2}$。

对于 $\hat{X}'$ 和 $\hat{X}''$ 这两个估计量，
我们可以获得 更紧的误差上界。我们把这一结果总结为如下定理：
\begin{theorem}\label{thm:error_rate}
当 $\sqrt{a} - \sqrt{b} > \sqrt{k}$ 时，
对于充分大的 $n$，我们有 
\begin{enumerate}
	\item 若 $\gamma > b$， $P_G(\hat{X}' \not\in S_k(X)) \leq (k-1+o(1))n^{g(\bar{\beta})}$；
	\item $P_G(\hat{X}'' \not\in S_k(X)) \leq \left((k-1)^2+o(1) \right)n^{2g(\bar{\beta})}$。
\end{enumerate}
\end{theorem}
因为 $g(\bar{\beta})<0$， 我们有大小关系 $n^{2g(\bar{\beta})} < n^{g(\bar{\beta})} < n^{g(\bar{\beta})/2}$。
从而 定理 \ref{thm:error_rate} 说明了在三个估计量中，
$P_e(\hat{X}'')$ 
的上界最紧。
这可以直观地理解为搜索空间缩小的结果。

定理 \ref{thm:error_rate} 的证明思路是对于 $\Dist(\bar{\sigma}, X) = 1, 2,\dots$，
分别考虑事件
$H(X) > H(\bar{\sigma})$发生的概率。
\newglossaryentry{bool_ineq}{name=布尔不等式, description={Boole's inequality}}
然后通过\gls{bool_ineq}， 这些概率可以相加。
关于估计量 $\hat{X}''$ 误差上界的研究早在\citet{abbe2015exact} 的工作中即有涉及，
但该工作只得到了一个比较松的上界 $n^{g(\bar{\beta})/4}$，且仅针对 $k=2$ 的情形。
对于一般的情形，
当条件
$\sqrt{a} - \sqrt{b} > \sqrt{k}$ 满足时，考虑到
$\tilde{g}(\beta) = 1- \frac{\left(\sqrt{a} - \sqrt{b}\right)^2}{k}$，
定理 \ref{thm:error_rate} 说明了  $\hat{X}'$ 和 $\hat{X}''$
均可实现
精确恢复。


估计量 $\hat{X}'$ 有一个参数 $\gamma$。
当 $\gamma$ 取特定的值时， 下面我们说明，$\hat{X}'$在渐近情形下
等价于 最大似然估计或最大模块度估计。
%以下分析从直观的角度说明了
%这种联系。

通过最大化对数似然函数可得到最大似然估计量。
由 式\eqref{eq:GmL}，该似然函数可以进一步写成：
\begin{equation}\label{eq:PG_energy}
	\log P_G(Z=z|X=\sigma) = -\log\frac{a}{b} \cdot H(\sigma) + C
\end{equation}

上式中$C$ 是一个和 $\sigma$ 无关的常数，
而 $H(\sigma)$ 由式\eqref{eq:energy}给出，
其中参数 $\gamma$ 的取值满足
\begin{equation}\label{eq:special_gamma_ML}
	\gamma \frac{\log n}{n} = \frac{1}{\log(a/b)}
	\left(\log \left(1-\B \right) - \log \left(1-\A \right) \right)	 
\end{equation}

当 $n$ 充分大时，我们有 $\gamma \to \gamma_{\mathrm{ML}} := \frac{a-b}{\log(a/b)}$。   
也即，
当 $\gamma = \gamma_{\mathrm{ML}}$时，
最大似然估计量 渐近等价于 $\hat{X}'$。

由式\eqref{eq:PG_energy}可知，
最大化似然函数等价于极小化能量$H(\sigma)$，
其中参数$\gamma$
由式\eqref{eq:special_gamma_ML}给出。
其次，
由式\eqref{eq:hatX_double_prime}，
极小化能量$H(\sigma)$
等价于$\min_{\sigma} \sum_{\{i,j\} \not\in E(G) } \delta(\sigma_i, \sigma_j)$。
考虑到在$W^*$的约束下，
$\sum_{1<i<j<n} \delta(\sigma_i, \sigma_j)$
是一个常数，式\eqref{eq:hatX_double_prime}又等价于
$-\sum_{ \{i,j\} \in E} \delta(\sigma_i, \sigma_j)$，
其与 式\eqref{eq:minimum_k_cut}只相差一个常数。
从而我们得到了最大似然算法和最小割问题在$W^*$约束
下的等价性，这个等价性不需要$n\to\infty$的渐近性条件也成立。


最大模块度估计量通过最大化式\eqref{eq:Q}而得到。
忽略常数项，关于标签向量 $\sigma$的模块度 $Q$
可以写成：
\begin{align}
Q(\sigma) = -\sum_{\{i,j\} \not\in E(G) } \frac{d_i d_j}{2 |E|}\delta(\sigma_i,\sigma_j) 
+ \sum_{\{i,j\} \in E(G) } \left(1 - \frac{d_i d_j}{2 |E|} \right) \delta(\sigma_i,\sigma_j)  \label{eq:Qtransform}
\end{align}

当$n$充分大时，平均意义上我们有 $d_i \sim  \frac{(a+(k-1)b)\log n}{k}, |E| \sim \frac{1}{2}n d_i$。
因此，我们有
$\frac{d_id_j}{2|E|} \to \gamma_{\mathrm{MQ}} \frac{\log n}{n} $。
从式 \eqref{eq:Qtransform}我们可以看到，
当 $\gamma = \gamma_{\mathrm{MQ}} = \frac{a+(k-1)b}{k}$ 且 $n\to \infty$时，
$Q(\sigma) \to -H(\sigma)$。
也即，当$\gamma = \gamma_{\mathrm{MQ}}$ 时，
最大模块度估计量渐近等价于
$\hat{X}'$ 。


通过$a>b$和 当$x>1$时的不等式 
 $x-1>\log x $，我们可以验证
  $\gamma_{\mathrm{MQ}} >b$ 且  $\gamma_{\mathrm{ML}} > b$。
  这说明 了
  最大似然估计和最大模块度估计都满足
  定理 \ref{thm:error_rate} 所述的精确恢复条件 $\gamma > b $。

\section{基于梅特罗波利斯采样的社团发现算法}\label{sec:ms}

由定理 \ref{thm:phase_transition} 可知，
如果我们直接从玻茨模型中采样，那么得到的样本大概率
与$X$一致。
然而，当$n$非常大时，按照式\eqref{eq:isingma}给出的分布精确采样是困难的，
因为状态空间的状态总数随着$n$以
$k^n$的速率指数增大。
因此，一定程度的近似是必要的，
为此，我们可以借助 \ref{sec:ising} 节介绍的梅特罗波利斯算法。 
经过若干次初始迭代后，梅特罗波利斯算法
每次产生的样本可视为从玻茨模型 采样的结果。
这个论断相关的理论研究主要是基于马尔可夫链。
在特定的条件下，
梅特罗波利斯算法生成的样本收敛到
马尔可夫链的稳态并且该稳态分布即为要近似的分布。
针对伊辛模型的不同变体，
之前的许多工作都表明了梅特罗波利斯算法采样的收敛性\cite{diaconis1998we}。
这里我们假设类似的收敛性结果可以推广到
形如 式\eqref{eq:isingma} 中描述的玻茨模型。

针对我们研究的模型和能量表达式 \eqref{eq:energy}，
我们对算法 \ref{alg:Metropolis} 进行
改写，得到
算法 \ref{alg:m}。
算法 \ref{alg:m} 要求
社团数量 $k$ 和参数 $\beta, \gamma$ 事先给定。
根据定理 \ref{thm:phase_transition}，我们需选取  $\beta>\beta^*, \gamma > b$
%\footnote{ $\beta^*$ 的定义参见式 \eqref{eq:beta_star} }
。
这里的 $a, b$
可以通过 定理 \ref{thm:ab12} 中提出的估计量$\hat{a},\hat{b}$进行近似。
此外，算法的迭代次数  $N$
也须事先确定。
\begin{algorithm}[H]
	\caption{针对玻茨模型的梅特罗波利斯算法} \label{alg:m}
	输入： 图 $G$、参数 $\beta,\gamma$ \\
	输出： $\hat{X} = \bar{\sigma}$
	\begin{algorithmic}[1]
		\STATE 随机初始化 $\bar{\sigma} \in W^n$ %\vskip 0.5em
		\FOR{$i=1,2,\dots, N$}
		\STATE 根据引理 \ref{lem:lemmaDiff}，
		随机选取 $s, r$ 并得到新的状态
		 $\bar{\sigma}'$
		 %\vskip 0.5em
		\STATE 通过 式\eqref{eq:DeltaH} 计算 $\upDelta H(r,s) = H(\bar{\sigma}') - H(\bar{\sigma})$ %\vskip 0.5em
		\IF{$\upDelta H(r,s)<0$}
		\STATE $\sigma_r \gets w^s \cdot \sigma_r$ %\vskip 0.5em
		\ELSE
		\STATE 以概率 $\exp(-\beta \upDelta H(r,s))$ 使得
			$\sigma_r \leftarrow w^s \cdot \sigma_r$，
			否则保持原状。 %\vskip 0.5em
		\ENDIF %\vskip 0.5em
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
 由 引理 \ref{lem:lemmaDiff}， $\upDelta H(r,s)$ 的计算需要 $O(\log n)$ 的时间。
有研究针对某种特殊的伊辛模型指出
在$N=O(n\log n)$的条件下 即可得到近似的比较好的样本\cite{mcmc}。
对于我们的模型，由于我们并不清楚 $ N = O(n\log n)$ 是否足够，
因此我们在数值实验中经验地选取 $N=O\left(n^2\right)$。
算法 \ref{alg:m} 总的时间复杂度为 $O\left(n^2 \log n \right)$。



借助梅特罗波利斯算法，
下面我们通过实验验证 定理 \ref{thm:phase_transition} 中  $\gamma > b$的情形。
我们选取了 $n=9000, k=2$，
通过蒙特卡罗采样的方法，我们可以得到准确率的经验计算公式为
$P_a(\hat{X}^*) = \frac{1}{m_1m_2}\sum_{i=1}^{m_1} \sum_{j=1}^{m_2} \mathbf{1}[\hat{X}^* = \pm X]$。
在这个公式中，
$m_1$ 是 由 随机块 模型产生随机图的次数，而
$m_2$ 是 对于一个特定的图，由算法 \ref{alg:m} 生成的连续样本的数量。
我们选取 $m_1=2100,m_2=6000$。这样的取值已相当大，
且由大数定律
保证 $P_a(\hat{X}^*)$ 是精确恢复概率的好的估计。
$P_a(\hat{X}^*)$ 随 $\beta$的变化在
图 \ref{fig:erh} 中给出。

\begin{figure}[ht!]
	\centering
		\includegraphics[width=0.6\textwidth]{beta_trans-2020-11-28.pdf}
		\caption{使用 $\hat{X}^*$ 进行社团发现精确恢复的准确率}\label{fig:erh}
\end{figure}


竖线 ($\beta=\beta^* \approx 0.198$)，
是 从式 \eqref{eq:beta_star} 计算得到的， 
代表了相变的临界值。
图 \ref{fig:erh} 中的坐标点 $(0.199,\frac{1}{2})$
可视为通过实验估计出的
相变点，它的横坐标接近
$\beta^*$。
绿线 $(\beta, n^{g(\beta)/2})$ 
表示当 $\beta>\beta^*$ 时准确率的理论下界，
而紫线
$(\beta, n^{-g(\beta)})$ 
表示当 $\beta<\beta^*$ 时准确率的理论上界。
仿真实验得到的相变曲线（蓝线）恰好介于这两线之间。
当 $n$ 变得更大时，可预见
相变曲线 将接近阶跃函数，该函数的值在
$\beta=\beta^*$ 处
从 0 跳变到 1。

\input{data/appendix_chap04}

\section{本章小结}\label{sec:summary_potts}
在本章中， 
我们首先给出了随机块模型参数的一致估计量 （定理 \ref{thm:ab12} ），
来推断参数$a,b$，而推断出的参数可用于后续算法设计中。其次，我们分析了
三个随机块模型节点标签的估计量，它们分别是基于玻茨模型的采样、极小化汉密尔顿能量
以及极小化带约束的能量函数。
在定理 \ref{thm:phase_transition} 和 \ref{thm:error_rate} 中
，我们给出了这三个估计量精确恢复的误差上界，并且研究了它们的误差上界之间的关系。
本章通过引入$k$状态的伊辛模型，
开辟了研究随机块模型精确恢复问题的新途径。

本部分的研究也存在一些不足之处。首先，针对算法误差的分析仅给出了上界，对于误差下界
由于尚存在技术性困难而没有相关结论。
其次，对于采样算法所需的采样次数
没有好的认识，在精度不变的前提下，算法 \ref{alg:m} 的时间复杂度存在提升空间。
最后，定义汉密尔顿能量函数的方法不止一种，
实验部分缺少和其他基于统计物理的社团发现方法的
对比性研究。

在本章研究的随机块模型的基础上，增加辅助信息，有助于提升社团发现算法的效率。
如何定量的刻画辅助信息带来的增益，将是下一章研究的重点。
另外，本章中使用到的误差上界分析等技术，也将在下一章中继续使用。


